{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149251b0",
   "metadata": {},
   "source": [
    "# MVE Axiom Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f9403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a17f59bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=\"\"\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56da1c2a",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f72154a",
   "metadata": {},
   "source": [
    "\n",
    "* Try to get a reasonable score?\n",
    "* TODO add batchnorm\n",
    "* TODO add residual connections\n",
    "* TODO add other directions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb5c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e45198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc4f38f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54f9f293",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398e10c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eholden/.pyenv/versions/3.7.5/lib/python3.7/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Embedding\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import GCNConv, Linear\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.transforms import to_undirected, ToUndirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "114bbc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(os.path.abspath('')).parent))\n",
    "\n",
    "import config\n",
    "from dataset import get_data_loader, BenchmarkType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ee2cc0",
   "metadata": {},
   "source": [
    "## CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7f0d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN_ID = '../id_files/train.txt'\n",
    "TRAIN_ID = '../id_files/validation.txt'\n",
    "\n",
    "VAL_ID = '../id_files/validation.txt'\n",
    "BENCHMARK_TYPE = BenchmarkType('deepmath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a0c6788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbf08057570>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234567)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e5a303",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb5db008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch_geometric.transforms.to_undirected.ToUndirected"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ToUndirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac45cfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: TorchMemoryDataset(2465)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[36912], edge_index=[2, 120812], premise_index=[842], conjecture_index=[64], name=[64], y=[842], batch=[36912], ptr=[65])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = get_data_loader(TRAIN_ID, BENCHMARK_TYPE, transform=ToUndirected())\n",
    "next(iter(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beee85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform = ToUndirected()\n",
    "transform = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e88261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "035c60c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: TorchMemoryDataset(2465)\n",
      "Dataset: TorchMemoryDataset(2465)\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data_loader(TRAIN_ID, BENCHMARK_TYPE, transform=transform)\n",
    "val_data = get_data_loader(VAL_ID, BENCHMARK_TYPE, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9529eafc",
   "metadata": {},
   "source": [
    "### Small check on a datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2715c4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[40357], edge_index=[2, 66926], premise_index=[842], conjecture_index=[64], name=[64], y=[842], batch=[40357], ptr=[65])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a591be71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[771], edge_index=[2, 1423], premise_index=[6], conjecture_index=[1], name='t41_setwop_2', y=[6])\n",
      "['edge_index', 'name', 'x', 'premise_index', 'conjecture_index', 'y']\n",
      "771\n",
      "1423\n",
      "1\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_data))[0]\n",
    "print(data)\n",
    "print(data.keys)\n",
    "print(data.num_nodes)\n",
    "print(data.num_edges)\n",
    "print(data.num_node_features)\n",
    "print(data.has_isolated_nodes())\n",
    "print(data.is_directed())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a13e22",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abd0528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_params = {flow: \"target_to_source\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9389cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_network(hidden_dim, task='binary', dropout_rate=0.0):\n",
    "    if task == 'binary':\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Dropout(dropout_rate), \n",
    "            nn.Linear(hidden_dim, 1)) # Two layer dense output network\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc5ccc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, num_convolutional_layers, dropout_rate=0.0, task='node'):\n",
    "        \n",
    "        super(GNNStack, self).__init__()\n",
    "        #self.flow = 'source_to_target'\n",
    "        self.flow = 'target_to_source'\n",
    "        \n",
    "        self.task = task\n",
    "        self.num_convolutional_layers = num_convolutional_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # Add embedding layer\n",
    "        self.node_embedding = Embedding(len(config.NODE_TYPE), hidden_dim)\n",
    "\n",
    "        # Add convolutional layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(self.num_convolutional_layers): \n",
    "            self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\n",
    "        \n",
    "        # Add normalisation layers (not after last convolution)\n",
    "        self.lns = nn.ModuleList()\n",
    "        for _ in range(self.num_convolutional_layers -1): \n",
    "            self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "            \n",
    "        # post-message-passing\n",
    "        self.post_mp = get_dense_network(hidden_dim, dropout_rate=self.dropout_rate)\n",
    "        \n",
    "        \n",
    "        #if not (self.task == 'node' or self.task == 'graph'):\n",
    "        #    raise RuntimeError('Unknown task.')\n",
    "\n",
    "        \n",
    "    def build_conv_model(self, input_dim, hidden_dim):\n",
    "        # refer to pytorch geometric nn module for different implementation of GNNs.\n",
    "        #if self.task == 'node':\n",
    "        return pyg_nn.GCNConv(input_dim, hidden_dim, flow=self.flow)\n",
    "        #else:\n",
    "        #    return pyg_nn.GINConv(nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
    "        #                          nn.ReLU(), nn.Linear(hidden_dim, hidden_dim)))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, premise_index = data.x, data.edge_index, data.premise_index    \n",
    "\n",
    "        \n",
    "        x = self.node_embedding(x)\n",
    "        \n",
    "        #if data.num_node_features == 0:\n",
    "        #  x = torch.ones(data.num_nodes, 1)\n",
    "\n",
    "        for i in range(self.num_convolutional_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            emb = x\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "            if not i == self.num_convolutional_layers - 1: # Apply normalisation\n",
    "                x = self.lns[i](x)\n",
    "\n",
    "        #if self.task == 'graph':\n",
    "        #    x = pyg_nn.global_mean_pool(x, batch)\n",
    "\n",
    "        # TODO should this be combined?\n",
    "        x = x[premise_index]\n",
    "        x = self.post_mp(x)\n",
    "        x = x.squeeze(-1)\n",
    "        return x\n",
    "\n",
    "        #\n",
    "        # return emb, F.log_softmax(x, dim=1) FIXME\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)\n",
    "    \n",
    "    \n",
    "model = GNNStack(hidden_dim=32, num_convolutional_layers=3, dropout_rate=0.25, task='graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d19c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e90ea7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3089efda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass GCN(torch.nn.Module):\\n    def __init__(self, hidden_channels):\\n        super().__init__()\\n        self.node_embedding = Embedding(len(config.NODE_TYPE), hidden_channels)\\n\\n\\n        self.conv1 = GCNConv(hidden_channels, hidden_channels)\\n        self.conv2 = GCNConv(hidden_channels, hidden_channels)\\n        \\n        self.linear = Linear(hidden_channels, 1)\\n        \\n\\n    def forward(self, input_batch):\\n        \\n        x = input_batch.x\\n        edge_index = input_batch.edge_index\\n        premise_index = input_batch.premise_index    \\n\\n        x = self.node_embedding(x)\\n\\n        x = self.conv1(x, edge_index)\\n        x = x.relu()\\n        \\n        x = F.dropout(x, p=0.5, training=self.training) # TODO add dropout parameter?\\n        \\n        x = self.conv2(x, edge_index)\\n        x = x.relu()\\n        \\n        x = x[premise_index]\\n        x = self.linear(x)\\n        \\n        # Remove inner axis\\n        x = x.squeeze(-1)\\n        \\n    \\n        return x\\n\\n    \\nmodel = GCN(hidden_channels=16)\\nprint(model)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.node_embedding = Embedding(len(config.NODE_TYPE), hidden_channels)\n",
    "\n",
    "\n",
    "        self.conv1 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        self.linear = Linear(hidden_channels, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        \n",
    "        x = input_batch.x\n",
    "        edge_index = input_batch.edge_index\n",
    "        premise_index = input_batch.premise_index    \n",
    "\n",
    "        x = self.node_embedding(x)\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training) # TODO add dropout parameter?\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = x[premise_index]\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        # Remove inner axis\n",
    "        x = x.squeeze(-1)\n",
    "        \n",
    "    \n",
    "        return x\n",
    "\n",
    "    \n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3f1bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24348ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afde9bf3",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "081eb353",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69431792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for data in train_data:  # Iterate in batches over the training dataset.\n",
    "        out = model(data)  # Perform a single forward pass. TODO change this\n",
    "\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "        \n",
    "        \n",
    "def test(loader):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data)\n",
    "        pred = torch.sigmoid(out).round().long()\n",
    "        \n",
    "        correct += data.y.eq(pred).sum().item()\n",
    "        \n",
    "        total_samples += len(pred)\n",
    "\n",
    "    return correct / total_samples  # Derive ratio of correct predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e484408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "516ceeb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.6499, Test Acc: 0.6499\n",
      "Epoch: 002, Train Acc: 0.6488, Test Acc: 0.6488\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1, 3):\n",
    "    train()\n",
    "    train_acc = test(train_data)\n",
    "    test_acc = test(val_data)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16656d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f675e4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986c23ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871690b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
