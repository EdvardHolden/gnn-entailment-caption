{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149251b0",
   "metadata": {},
   "source": [
    "# MVE Axiom Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f9403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a17f59bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=\"\"\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3924fa30",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09bbeaf",
   "metadata": {},
   "source": [
    "\n",
    "* Try to get a reasonable score?\n",
    "* TODO add batchnorm\n",
    "* TODO add residual connections\n",
    "* TODO add other directions? [done]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667c466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da403f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f587d695",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398e10c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eholden/.pyenv/versions/3.7.5/lib/python3.7/site-packages/torch/cuda/__init__.py:80: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Embedding\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import GCNConv, Linear\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.transforms import to_undirected, ToUndirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "626814a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path(os.path.abspath(\"\")).parent))\n",
    "\n",
    "import config\n",
    "from dataset import get_data_loader, BenchmarkType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15506878",
   "metadata": {},
   "source": [
    "## CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d81ad412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_ID = '../id_files/train.txt'\n",
    "TRAIN_ID = \"../id_files/validation.txt\"\n",
    "\n",
    "VAL_ID = \"../id_files/validation.txt\"\n",
    "BENCHMARK_TYPE = BenchmarkType(\"deepmath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b45e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4b14098570>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234567)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb7e581",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fb7de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_params = {'transform': ToUndirected()}\n",
    "dataset_params = {\"transform\": None}\n",
    "\n",
    "# transform = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f39d8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: TorchMemoryDataset(2465)\n",
      "Dataset: TorchMemoryDataset(2465)\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data_loader(TRAIN_ID, BENCHMARK_TYPE, **dataset_params)\n",
    "val_data = get_data_loader(VAL_ID, BENCHMARK_TYPE, **dataset_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9679046",
   "metadata": {},
   "source": [
    "## Data point check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1af35668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[36912], edge_index=[2, 60406], premise_index=[842], conjecture_index=[64], name=[64], y=[842], batch=[36912], ptr=[65])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "724ecb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[164], edge_index=[2, 258], premise_index=[4], conjecture_index=[1], name='t104_zfmisc_1', y=[4])\n",
      "['name', 'x', 'edge_index', 'premise_index', 'conjecture_index', 'y']\n",
      "164\n",
      "258\n",
      "1\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_data))[0]\n",
    "print(data)\n",
    "print(data.keys)\n",
    "print(data.num_nodes)\n",
    "print(data.num_edges)\n",
    "print(data.num_node_features)\n",
    "print(data.has_isolated_nodes())\n",
    "print(data.is_directed())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e050678e",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2316008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_output_network(hidden_dim, task, dropout_rate=0.0):\n",
    "    if task == \"premise\":\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(dropout_rate), nn.Linear(hidden_dim, 1)\n",
    "        )  # Two layer dense output network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda9bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "114ffeb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.batchnorm.BatchNorm1d"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.BatchNorm1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6034f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCN_NORMALISATION = {\"batch\": nn.BatchNorm1d, \"layer\": nn.LayerNorm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d218899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCNDirectional(\n",
       "  (convs): ModuleList(\n",
       "    (0): GCNConv(32, 32)\n",
       "    (1): GCNConv(32, 32)\n",
       "    (2): GCNConv(32, 32)\n",
       "  )\n",
       "  (lns): ModuleList(\n",
       "    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GCNDirectional(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, hidden_dim, num_convolutional_layers, dropout_rate, normalisation, skip_connection\n",
    "    ):  # TODO also add normalisation\n",
    "        super(GCNDirectional, self).__init__()\n",
    "\n",
    "        self.flow = \"target_to_source\"  # Sets direction to bottom up\n",
    "        # self.flow = 'source_to_target' # Not sensible, premise nodes remains unchanged\n",
    "\n",
    "        # Set variables\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_convolutional_layers = num_convolutional_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.skip_connection = skip_connection\n",
    "\n",
    "        # Add convolutional layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(self.num_convolutional_layers):\n",
    "            self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\n",
    "\n",
    "        # Add normalisation layers used in between graph convolutions\n",
    "        if normalisation is None:\n",
    "            self.lns = None\n",
    "        else:\n",
    "            self.normaliser = GCN_NORMALISATION[normalisation]\n",
    "            self.lns = nn.ModuleList()\n",
    "            for _ in range(self.num_convolutional_layers - 1):\n",
    "                # self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "                self.lns.append(self.normaliser(hidden_dim))\n",
    "\n",
    "    def build_conv_model(self, input_dim, hidden_dim):\n",
    "        return pyg_nn.GCNConv(input_dim, hidden_dim, flow=self.flow)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        # Iterate over each convolutional sequence\n",
    "        for i in range(self.num_convolutional_layers):\n",
    "\n",
    "            conv_out = self.convs[i](x, edge_index)\n",
    "            # Check if applying skip connection\n",
    "            if self.skip_connection:\n",
    "                x = x + conv_out\n",
    "            else:\n",
    "                x = conv_out\n",
    "\n",
    "            emb = x\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "            if self.lns is not None and not i == self.num_convolutional_layers - 1:  # Apply normalisation\n",
    "                x = self.lns[i](x)\n",
    "\n",
    "        return emb, x\n",
    "\n",
    "\n",
    "sub = GCNDirectional(\n",
    "    hidden_dim=32, num_convolutional_layers=3, dropout_rate=0.25, normalisation=\"batch\", skip_connection=False\n",
    ")\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26016846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8021b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO should variables not used in this very module actually be saved here?\n",
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim,\n",
    "        num_convolutional_layers,\n",
    "        dropout_rate=0.0,\n",
    "        task=\"premise\",\n",
    "        normalisation=\"layer\",\n",
    "        skip_connection=True,\n",
    "    ):\n",
    "        super(GNNStack, self).__init__()\n",
    "\n",
    "        # Set variables\n",
    "        self.task = task\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Add embedding layer\n",
    "        self.node_embedding = Embedding(len(config.NODE_TYPE), hidden_dim)\n",
    "\n",
    "        # Add GCN layer\n",
    "        self.gcn = GCNDirectional(\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            num_convolutional_layers=num_convolutional_layers,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            normalisation=normalisation,\n",
    "            skip_connection=skip_connection,\n",
    "        )\n",
    "\n",
    "        # Post-message-passing\n",
    "        self.post_mp = get_dense_output_network(hidden_dim, task=self.task, dropout_rate=self.dropout_rate)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, premise_index = data.x, data.edge_index, data.premise_index\n",
    "\n",
    "        x = self.node_embedding(x)\n",
    "\n",
    "        emb, x = self.gcn(x, edge_index)\n",
    "\n",
    "        # if self.task == 'graph':\n",
    "        #    x = pyg_nn.global_mean_pool(x, batch)\n",
    "\n",
    "        # TODO should this be combined?\n",
    "        x = x[premise_index]\n",
    "        x = self.post_mp(x)\n",
    "        x = x.squeeze(-1)\n",
    "\n",
    "        return emb, x\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)\n",
    "\n",
    "\n",
    "model = GNNStack(hidden_dim=32, num_convolutional_layers=3, dropout_rate=0.25, task=\"premise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b98b826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNStack(\n",
      "  (node_embedding): Embedding(15, 32)\n",
      "  (gcn): GCNDirectional(\n",
      "    (convs): ModuleList(\n",
      "      (0): GCNConv(32, 32)\n",
      "      (1): GCNConv(32, 32)\n",
      "      (2): GCNConv(32, 32)\n",
      "    )\n",
      "    (lns): ModuleList(\n",
      "      (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (post_mp): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (1): Dropout(p=0.25, inplace=False)\n",
      "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee52ea03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b3740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2985c979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82dfdfcb",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "081eb353",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69431792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for data in train_data:  # Iterate in batches over the training dataset.\n",
    "        _, out = model(data)  # Perform a single forward pass. TODO change this\n",
    "\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        _, out = model(data)\n",
    "        pred = torch.sigmoid(out).round().long()\n",
    "\n",
    "        correct += data.y.eq(pred).sum().item()\n",
    "\n",
    "        total_samples += len(pred)\n",
    "\n",
    "    return correct / total_samples  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa6e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3cf5dca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.5941, Test Acc: 0.5941\n",
      "Epoch: 002, Train Acc: 0.6389, Test Acc: 0.6389\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 3):\n",
    "    train()\n",
    "    train_acc = test(train_data)\n",
    "    test_acc = test(val_data)\n",
    "    print(f\"Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16656d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9db64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2f782b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e92eeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass GCN(torch.nn.Module):\\n    def __init__(self, hidden_channels):\\n        super().__init__()\\n        self.node_embedding = Embedding(len(config.NODE_TYPE), hidden_channels)\\n\\n\\n        self.conv1 = GCNConv(hidden_channels, hidden_channels)\\n        self.conv2 = GCNConv(hidden_channels, hidden_channels)\\n        \\n        self.linear = Linear(hidden_channels, 1)\\n        \\n\\n    def forward(self, input_batch):\\n        \\n        x = input_batch.x\\n        edge_index = input_batch.edge_index\\n        premise_index = input_batch.premise_index    \\n\\n        x = self.node_embedding(x)\\n\\n        x = self.conv1(x, edge_index)\\n        x = x.relu()\\n        \\n        x = F.dropout(x, p=0.5, training=self.training) # TODO add dropout parameter?\\n        \\n        x = self.conv2(x, edge_index)\\n        x = x.relu()\\n        \\n        x = x[premise_index]\\n        x = self.linear(x)\\n        \\n        # Remove inner axis\\n        x = x.squeeze(-1)\\n        \\n    \\n        return x\\n\\n    \\nmodel = GCN(hidden_channels=16)\\nprint(model)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.node_embedding = Embedding(len(config.NODE_TYPE), hidden_channels)\n",
    "\n",
    "\n",
    "        self.conv1 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        self.linear = Linear(hidden_channels, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        \n",
    "        x = input_batch.x\n",
    "        edge_index = input_batch.edge_index\n",
    "        premise_index = input_batch.premise_index    \n",
    "\n",
    "        x = self.node_embedding(x)\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training) # TODO add dropout parameter?\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = x[premise_index]\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        # Remove inner axis\n",
    "        x = x.squeeze(-1)\n",
    "        \n",
    "    \n",
    "        return x\n",
    "\n",
    "    \n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
