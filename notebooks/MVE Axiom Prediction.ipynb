{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149251b0",
   "metadata": {},
   "source": [
    "# MVE Axiom Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f9403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a17f59bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=\"\"\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c37aa",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad6335a",
   "metadata": {},
   "source": [
    "* Add model parameters\n",
    "* Add other model definition from script\n",
    "* Try to get a reasonable score?\n",
    "* TODO add batchnorm\n",
    "* TODO add dropout parameter\n",
    "* TODO add residual connections\n",
    "* TODO add other directions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820a4fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc70510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631c7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b473383c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "398e10c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Embedding\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import GCNConv, Linear\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as pyg_nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "731907d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(os.path.abspath('')).parent))\n",
    "\n",
    "import config\n",
    "from dataset import get_data_loader, BenchmarkType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b816737b",
   "metadata": {},
   "source": [
    "## CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13c4cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN_ID = '../id_files/train.txt'\n",
    "TRAIN_ID = '../id_files/validation.txt'\n",
    "\n",
    "VAL_ID = '../id_files/validation.txt'\n",
    "BENCHMARK_TYPE = BenchmarkType('deepmath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c0ec16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0904037610>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234567)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be5c02",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94f35d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: TorchMemoryDataset(2465)\n",
      "Dataset: TorchMemoryDataset(2465)\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data_loader(TRAIN_ID, BENCHMARK_TYPE)\n",
    "val_data = get_data_loader(VAL_ID, BENCHMARK_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6beccc",
   "metadata": {},
   "source": [
    "### Small check on a datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66bd7d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[170], edge_index=[2, 268], premise_index=[2], conjecture_index=[1], name='t65_topalg_1', y=[2])\n",
      "['x', 'name', 'y', 'premise_index', 'edge_index', 'conjecture_index']\n",
      "170\n",
      "268\n",
      "1\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_data))[0]\n",
    "print(data)\n",
    "print(data.keys)\n",
    "print(data.num_nodes)\n",
    "print(data.num_edges)\n",
    "print(data.num_node_features)\n",
    "print(data.has_isolated_nodes())\n",
    "print(data.is_directed())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e734822",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0de714b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d494f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, task='node'):\n",
    "        \n",
    "        super(GNNStack, self).__init__()\n",
    "        self.task = task\n",
    "        \n",
    "        self.dropout = 0.25\n",
    "        self.num_layers = 3\n",
    "        \n",
    "        self.node_embedding = Embedding(len(config.NODE_TYPE), hidden_dim)\n",
    "\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        #self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\n",
    "        for _ in range(self.num_layers): \n",
    "            self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\n",
    "        \n",
    "        self.lns = nn.ModuleList()\n",
    "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        # post-message-passing\n",
    "        # TODO make a seprate function?\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(self.dropout), \n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "        \n",
    "        \n",
    "        #if not (self.task == 'node' or self.task == 'graph'):\n",
    "        #    raise RuntimeError('Unknown task.')\n",
    "\n",
    "        \n",
    "    def build_conv_model(self, input_dim, hidden_dim):\n",
    "        # refer to pytorch geometric nn module for different implementation of GNNs.\n",
    "        if self.task == 'node':\n",
    "            return pyg_nn.GCNConv(input_dim, hidden_dim)\n",
    "        else:\n",
    "            return pyg_nn.GINConv(nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
    "                                  nn.ReLU(), nn.Linear(hidden_dim, hidden_dim)))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, premise_index = data.x, data.edge_index, data.premise_index    \n",
    "\n",
    "        \n",
    "        x = self.node_embedding(x)\n",
    "        \n",
    "        #if data.num_node_features == 0:\n",
    "        #  x = torch.ones(data.num_nodes, 1)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            emb = x\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            if not i == self.num_layers - 1:\n",
    "                x = self.lns[i](x)\n",
    "\n",
    "        #if self.task == 'graph':\n",
    "        #    x = pyg_nn.global_mean_pool(x, batch)\n",
    "\n",
    "        # TODO should this be combined?\n",
    "        x = x[premise_index]\n",
    "        x = self.post_mp(x)\n",
    "        x = x.squeeze(-1)\n",
    "        return x\n",
    "\n",
    "        #\n",
    "        # return emb, F.log_softmax(x, dim=1) FIXME\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)\n",
    "    \n",
    "    \n",
    "model = GNNStack(hidden_dim=32, output_dim=1, task='graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8908d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0861309c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dfc19d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (node_embedding): Embedding(15, 16)\n",
      "  (conv1): GCNConv(16, 16)\n",
      "  (conv2): GCNConv(16, 16)\n",
      "  (linear): Linear(16, 1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.node_embedding = Embedding(len(config.NODE_TYPE), hidden_channels)\n",
    "\n",
    "\n",
    "        self.conv1 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        self.linear = Linear(hidden_channels, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        \n",
    "        x = input_batch.x\n",
    "        edge_index = input_batch.edge_index\n",
    "        premise_index = input_batch.premise_index    \n",
    "\n",
    "        x = self.node_embedding(x)\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training) # TODO add dropout parameter?\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = x[premise_index]\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        # Remove inner axis\n",
    "        x = x.squeeze(-1)\n",
    "        \n",
    "    \n",
    "        return x\n",
    "\n",
    "    \n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a49d06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df6908e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cab5c73d",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "081eb353",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "69431792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for data in train_data:  # Iterate in batches over the training dataset.\n",
    "        out = model(data)  # Perform a single forward pass. TODO change this\n",
    "\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "        \n",
    "        \n",
    "def test(loader):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data)\n",
    "        pred = torch.sigmoid(out).round().long()\n",
    "        \n",
    "        correct += data.y.eq(pred).sum().item()\n",
    "        \n",
    "        total_samples += len(pred)\n",
    "\n",
    "    return correct / total_samples  # Derive ratio of correct predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa7ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4c98c910",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.5000, Test Acc: 0.5000\n",
      "Epoch: 002, Train Acc: 0.5000, Test Acc: 0.5000\n",
      "Epoch: 003, Train Acc: 0.5000, Test Acc: 0.5000\n",
      "Epoch: 004, Train Acc: 0.5000, Test Acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1, 5):\n",
    "    train()\n",
    "    train_acc = test(train_data)\n",
    "    test_acc = test(val_data)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16656d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f38823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d0831f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f09a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
