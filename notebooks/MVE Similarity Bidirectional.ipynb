{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149251b0",
   "metadata": {},
   "source": [
    "# MVE Axiom Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a6ff94",
   "metadata": {},
   "source": [
    "% https://colab.research.google.com/drive/1DIQm9rOx2mT1bZETEeVUThxcrP1RKqAn#scrollTo=IS1dPinuyPCy reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a17f59bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env CUDA_VISIBLE_DEVICES=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3924fa30",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09bbeaf",
   "metadata": {},
   "source": [
    "\n",
    "* Try to get a reasonable score?\n",
    "* TODO add batchnorm [done]\n",
    "* TODO add residual connections [done]\n",
    "* TODO add other directions? [done]\n",
    "* TODO add FileWriter [done]\n",
    "* TODO separate itno functions [done]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667c466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da403f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f587d695",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398e10c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Embedding\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import GCNConv, Linear\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.transforms import to_undirected, ToUndirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626814a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path(os.path.abspath(\"\")).parent))\n",
    "\n",
    "import config\n",
    "from dataset import get_data_loader, BenchmarkType\n",
    "from stats_writer import Writer\n",
    "from dataset import LearningTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29143ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb5c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import TorchMemoryDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12b352ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kwargs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m TorchMemoryDataset(VAL_ID,  BenchmarkType(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepmath\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mkwargs\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kwargs' is not defined"
     ]
    }
   ],
   "source": [
    "TorchMemoryDataset(VAL_ID,  BenchmarkType(\"deepmath\"), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad303964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import ToUndirected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a146cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e064866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = TorchMemoryDataset(VAL_ID,  BenchmarkType(\"deepmath\"), **{\"transform\": ToUndirected()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d97a1b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[203], edge_index=[2, 692], premise_index=[2], conjecture_index=[1], name='t30_glib_001', y=[2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87927088",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = TorchMemoryDataset(VAL_ID,  BenchmarkType(\"deepmath\"), transform= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f46b251f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchMemoryDataset(2465)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d83ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc511eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d60d210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = TorchMemoryDataset(VAL_ID,  BenchmarkType(\"deepmath\"), **{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b2e5ec14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0].is_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50a229d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0].is_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb6067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf2403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15506878",
   "metadata": {},
   "source": [
    "## CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d81ad412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_ID = '../id_files/train.txt'\n",
    "TRAIN_ID = \"../id_files/validation.txt\"\n",
    "\n",
    "VAL_ID = \"../id_files/validation.txt\"\n",
    "BENCHMARK_TYPE = BenchmarkType(\"deepmath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b45e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4d20529e70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234567)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb7e581",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fb7de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_params = {'transform': ToUndirected()}\n",
    "dataset_params = {\"transform\": None}\n",
    "\n",
    "# transform = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f39d8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: TorchMemoryDataset(2465)\n"
     ]
    }
   ],
   "source": [
    "data_instance = get_data_loader(TRAIN_ID, BENCHMARK_TYPE, **dataset_params)\n",
    "# val_data = get_data_loader(VAL_ID, BENCHMARK_TYPE, **dataset_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9679046",
   "metadata": {},
   "source": [
    "## Data point check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1af35668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[36912], edge_index=[2, 60406], premise_index=[842], conjecture_index=[64], name=[64], y=[842], batch=[36912], ptr=[65])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "724ecb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[164], edge_index=[2, 258], premise_index=[4], conjecture_index=[1], name='t104_zfmisc_1', y=[4])\n",
      "['y', 'edge_index', 'x', 'conjecture_index', 'premise_index', 'name']\n",
      "164\n",
      "258\n",
      "1\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(data_instance))[0]\n",
    "print(data)\n",
    "print(data.keys)\n",
    "print(data.num_nodes)\n",
    "print(data.num_edges)\n",
    "print(data.num_node_features)\n",
    "print(data.has_isolated_nodes())\n",
    "print(data.is_directed())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e050678e",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2316008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_output_network(no_dense_layers, hidden_dim, task, dropout_rate):\n",
    "    # TODO set TYPE\n",
    "    if task == \"premise\":\n",
    "        return DenseOutput(hidden_dim, no_dense_layers, hidden_dim, dropout_rate)\n",
    "    elif task == \"similarity\":\n",
    "        return DenseOutput(hidden_dim * 2, no_dense_layers, hidden_dim, dropout_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"No dense output network for: {task}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4338d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e7c47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ed991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00ea01bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseOutput(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int, no_dense_layers: int, hidden_dim: int, dropout_rate: float):\n",
    "        super(DenseOutput, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.no_dense_layers = no_dense_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self._build_network()\n",
    "\n",
    "    def _build_network(self):\n",
    "\n",
    "        if self.no_dense_layers <= 0:  # No hidden layer\n",
    "            self.out = nn.Linear(self.input_dim, 1)\n",
    "        else:\n",
    "            # Add input layer\n",
    "            self.lin = nn.ModuleList()\n",
    "            self.lin.append(nn.Linear(self.input_dim, self.hidden_dim))\n",
    "            # Ad dense layers\n",
    "            for _ in range(self.no_dense_layers - 1):\n",
    "                self.lin.append(nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "            # Add output layer\n",
    "            self.out = nn.Linear(self.hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # TODO move this to Stack Model?\n",
    "        # Extract premises\n",
    "        # x = x[premise_index]\n",
    "\n",
    "        # Dense feedforward\n",
    "        for i in range(self.no_dense_layers):\n",
    "            x = self.lin[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "        # Output layer\n",
    "        x = self.out(x)\n",
    "        x = x.squeeze(-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e288e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0868abde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e919359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bd8714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84a57fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda9bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6034f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCN_NORMALISATION = {\"batch\": nn.BatchNorm1d, \"layer\": nn.LayerNorm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e1749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8838a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_normalisation_layers(normaliser, hidden_dim, num_normalisation_layers):\n",
    "\n",
    "    lns = nn.ModuleList()\n",
    "    for _ in range(num_normalisation_layers):\n",
    "        lns.append(normaliser(hidden_dim))\n",
    "    return lns\n",
    "\n",
    "\n",
    "def build_conv_model(num_convolutional_layers, hidden_dim, flow):\n",
    "\n",
    "    convs = nn.ModuleList()\n",
    "    for _ in range(num_convolutional_layers):\n",
    "        convs.append(get_conv_layer(hidden_dim, hidden_dim, flow))\n",
    "\n",
    "    return convs\n",
    "\n",
    "\n",
    "def get_conv_layer(input_dim, hidden_dim, flow):\n",
    "    return pyg_nn.GCNConv(input_dim, hidden_dim, flow=flow)\n",
    "\n",
    "\n",
    "def build_merge_linear_layers(num_linear_layers, hidden_dim):\n",
    "\n",
    "    lin = nn.ModuleList()\n",
    "    for _ in range(num_linear_layers):\n",
    "        lin.append(Linear(hidden_dim * 2, hidden_dim))\n",
    "\n",
    "    return lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d218899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCNDirectional(\n",
       "  (convs): ModuleList(\n",
       "    (0): GCNConv(32, 32)\n",
       "    (1): GCNConv(32, 32)\n",
       "    (2): GCNConv(32, 32)\n",
       "  )\n",
       "  (lns): ModuleList(\n",
       "    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GCNDirectional(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, num_convolutional_layers, dropout_rate, normalisation, skip_connection):\n",
    "        super(GCNDirectional, self).__init__()\n",
    "\n",
    "        self.flow = \"target_to_source\"  # Sets direction to bottom up\n",
    "\n",
    "        # Set variables\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_convolutional_layers = num_convolutional_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.skip_connection = skip_connection\n",
    "\n",
    "        # Add convolutional layers\n",
    "        self.convs = build_conv_model(num_convolutional_layers, hidden_dim, self.flow)\n",
    "\n",
    "        # Add normalisation layers used in between graph convolutions\n",
    "        if normalisation is None:\n",
    "            self.lns = None\n",
    "        else:\n",
    "            self.normaliser = GCN_NORMALISATION[normalisation]\n",
    "            self.lns = build_normalisation_layers(self.normaliser, hidden_dim, num_convolutional_layers - 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        # Iterate over each convolutional sequence\n",
    "        for i in range(self.num_convolutional_layers):\n",
    "\n",
    "            conv_out = self.convs[i](x, edge_index)\n",
    "            # Check if applying skip connection\n",
    "            if self.skip_connection:\n",
    "                x = x + conv_out\n",
    "            else:\n",
    "                x = conv_out\n",
    "\n",
    "            emb = x\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "            if self.lns is not None and not i == self.num_convolutional_layers - 1:  # Apply normalisation\n",
    "                x = self.lns[i](x)\n",
    "\n",
    "        return emb, x\n",
    "\n",
    "\n",
    "sub = GCNDirectional(\n",
    "    hidden_dim=32, num_convolutional_layers=3, dropout_rate=0.25, normalisation=\"batch\", skip_connection=False\n",
    ")\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43775f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16bbf39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dbc42b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b5bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cc71979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCNBiDirectional(\n",
       "  (convs_up): ModuleList(\n",
       "    (0): GCNConv(32, 32)\n",
       "    (1): GCNConv(32, 32)\n",
       "    (2): GCNConv(32, 32)\n",
       "  )\n",
       "  (convs_down): ModuleList(\n",
       "    (0): GCNConv(32, 32)\n",
       "    (1): GCNConv(32, 32)\n",
       "    (2): GCNConv(32, 32)\n",
       "  )\n",
       "  (lns): ModuleList(\n",
       "    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (linear): ModuleList(\n",
       "    (0): Linear(64, 32, bias=True)\n",
       "    (1): Linear(64, 32, bias=True)\n",
       "    (2): Linear(64, 32, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GCNBiDirectional(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, num_convolutional_layers, dropout_rate, normalisation, skip_connection):\n",
    "        super(GCNBiDirectional, self).__init__()\n",
    "\n",
    "        # Set variables\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_convolutional_layers = num_convolutional_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.skip_connection = skip_connection\n",
    "\n",
    "        # Add convolutional layers\n",
    "        self.convs_up = build_conv_model(num_convolutional_layers, hidden_dim, flow=\"source_to_target\")\n",
    "        self.convs_down = build_conv_model(num_convolutional_layers, hidden_dim, flow=\"target_to_source\")\n",
    "\n",
    "        # Add normalisation layers used in between graph convolutions\n",
    "        if normalisation is None:\n",
    "            self.lns = None\n",
    "        else:\n",
    "            self.normaliser = GCN_NORMALISATION[normalisation]\n",
    "            self.lns = build_normalisation_layers(self.normaliser, hidden_dim, num_convolutional_layers - 1)\n",
    "\n",
    "        # Add Linear layers\n",
    "        self.linear = build_merge_linear_layers(num_convolutional_layers, hidden_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        # Iterate over each convolutional sequence\n",
    "        for i in range(self.num_convolutional_layers):\n",
    "\n",
    "            # Apply convolutions\n",
    "            x_up = self.convs_up[i](x, edge_index)\n",
    "            x_down = self.convs_down[i](x, edge_index)\n",
    "\n",
    "            # Check if applying skip connection\n",
    "            if self.skip_connection:\n",
    "                x_up = x + x_up\n",
    "                x_down = x + x_down\n",
    "\n",
    "            # Concat convolutions\n",
    "            x = torch.cat((x_up, x_down), dim=1)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "            # Merge through linear\n",
    "            x = self.linear[i](x)\n",
    "            emb = x\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "\n",
    "            # Normalise, if set\n",
    "            if self.lns is not None and not i == self.num_convolutional_layers - 1:  # Apply normalisation\n",
    "                x = self.lns[i](x)\n",
    "\n",
    "        return emb, x\n",
    "\n",
    "\n",
    "sub = GCNBiDirectional(\n",
    "    hidden_dim=32, num_convolutional_layers=3, dropout_rate=0.25, normalisation=\"batch\", skip_connection=False\n",
    ")\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb21e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7854bd26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79e8dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a superclass as the wrapper? Only really need to change the foward function right? And add some more stuff to the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4108522a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f9207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a18e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85813b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b7539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c175dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8021b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim,\n",
    "        num_convolutional_layers,\n",
    "        no_dense_layers,\n",
    "        direction,\n",
    "        dropout_rate=0.0,\n",
    "        task=\"premise\",\n",
    "        normalisation=\"layer\",\n",
    "        skip_connection=True,\n",
    "    ):\n",
    "        super(GNNStack, self).__init__()\n",
    "\n",
    "        # Set variables\n",
    "        self.task = task\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Add embedding layer\n",
    "        self.node_embedding = Embedding(len(config.NODE_TYPE), hidden_dim)\n",
    "\n",
    "        # Add GCN layer\n",
    "        if direction == \"single\":\n",
    "            gcn_base = GCNDirectional\n",
    "        elif direction == \"separate\":\n",
    "            gcn_base = GCNBiDirectional\n",
    "        else:\n",
    "            raise ValueError(f\"Unkown gcn direction {direction}\")\n",
    "\n",
    "        self.gcn = gcn_base(\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            num_convolutional_layers=num_convolutional_layers,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            normalisation=normalisation,\n",
    "            skip_connection=skip_connection,\n",
    "        )\n",
    "\n",
    "        # Post-message-passing\n",
    "        self.post_mp = get_dense_output_network(\n",
    "            no_dense_layers, hidden_dim, task=self.task, dropout_rate=self.dropout_rate\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, premise_index = data.x, data.edge_index, data.premise_index\n",
    "\n",
    "        x = self.node_embedding(x)\n",
    "\n",
    "        emb, x = self.gcn(x, edge_index)\n",
    "\n",
    "        if self.task == \"premise\":\n",
    "            x = self.post_mp(x, premise_index)\n",
    "\n",
    "            # elif self.task == 'graph':\n",
    "            #    x = pyg_nn.global_mean_pool(x, batch)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        return emb, x\n",
    "\n",
    "    # def loss(self, pred, label):\n",
    "    #    return F.nll_loss(pred, label)\n",
    "\n",
    "\n",
    "test_model = GNNStack(\n",
    "    hidden_dim=32,\n",
    "    num_convolutional_layers=3,\n",
    "    no_dense_layers=1,\n",
    "    direction=\"single\",\n",
    "    dropout_rate=0.25,\n",
    "    task=\"premise\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b98b826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNStack(\n",
      "  (node_embedding): Embedding(15, 32)\n",
      "  (gcn): GCNDirectional(\n",
      "    (convs): ModuleList(\n",
      "      (0): GCNConv(32, 32)\n",
      "      (1): GCNConv(32, 32)\n",
      "      (2): GCNConv(32, 32)\n",
      "    )\n",
      "    (lns): ModuleList(\n",
      "      (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "      (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (post_mp): DenseOutput(\n",
      "    (lin): ModuleList(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (out): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee52ea03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8cba6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de219a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7a515bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add Graph difference AND add extra network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5dc9c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fcccd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.functional.mse_loss(input: torch.Tensor, target: torch.Tensor, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "345b3740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_dim': 32, 'num_convolutional_layers': 3, 'no_dense_layers': 1, 'direction': 'single', 'dropout_rate': 0.25, 'task': 'premise'}\n"
     ]
    }
   ],
   "source": [
    "model = GNNStackSiamese(\n",
    "    hidden_dim=32,\n",
    "    num_convolutional_layers=3,\n",
    "    no_dense_layers=1,\n",
    "    direction=\"single\",\n",
    "    dropout_rate=0.25,\n",
    "    task=\"premise\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2985c979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'similarity'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e23a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b301b938",
   "metadata": {},
   "source": [
    "Lets only have one output layer for now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d8f7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6036aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82dfdfcb",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081eb353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69431792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, criterion, optimizer):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for data in train_data:  # Iterate in batches over the training dataset.\n",
    "        _, out = model(data)  # Perform a single forward pass. TODO change this\n",
    "\n",
    "        # loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss = criterion(out, data.y, reduction=\"mean\")  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "\n",
    "def test(model, test_data, criterion, writer, testing: bool):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in test_data:  # Iterate in batches over the training/test dataset.\n",
    "        _, out = model(data)\n",
    "\n",
    "        pred = torch.sigmoid(out).round().long()\n",
    "        # correct += data.y.eq(pred).sum().item()\n",
    "\n",
    "        loss = criterion(out, data.y, reduction=\"sum\")\n",
    "        correct = loss\n",
    "\n",
    "        total_loss += loss\n",
    "        total_samples += len(pred)\n",
    "\n",
    "    acc_score = correct / total_samples  # Derive ratio of correct predictions.\n",
    "    total_loss /= total_samples\n",
    "    total_loss = total_loss.item()\n",
    "\n",
    "    # print(total_loss)\n",
    "    acc_score = total_loss\n",
    "\n",
    "    if testing:\n",
    "        writer.report_val_score(acc_score)\n",
    "        writer.report_val_loss(total_loss)\n",
    "    else:\n",
    "        writer.report_train_score(acc_score)\n",
    "        writer.report_train_loss(total_loss)\n",
    "\n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa6e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "714b9721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupervised dataset: 100\n",
      "Unsupervised dataset: 100\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data_loader(TRAIN_ID, BENCHMARK_TYPE, task=LearningTask.SIMILARITY, **dataset_params)\n",
    "val_data = get_data_loader(VAL_ID, BENCHMARK_TYPE, task=LearningTask.SIMILARITY, **dataset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798c77c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b73bbe03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LearningTask.SIMILARITY: 'similarity'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LearningTask.SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a9f9240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.functional.mse_loss(input: torch.Tensor, target: torch.Tensor, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b3414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a4e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3cf5dca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training\n",
      "Epoch: 001, Train Score: 1613.3157, Test Score: 1613.3157\n",
      "Epoch: 002, Train Score: 977.2343, Test Score: 977.2342\n",
      "Epoch: 003, Train Score: 527.2117, Test Score: 527.2117\n",
      "Epoch: 004, Train Score: 812.5084, Test Score: 812.5084\n",
      "Epoch: 005, Train Score: 1410.8558, Test Score: 1410.8560\n",
      "Epoch: 006, Train Score: 1041.7841, Test Score: 1041.7841\n",
      "Epoch: 007, Train Score: 604.8157, Test Score: 604.8156\n",
      "Epoch: 008, Train Score: 504.1052, Test Score: 504.1052\n",
      "Epoch: 009, Train Score: 521.9355, Test Score: 521.9355\n",
      "Epoch: 010, Train Score: 517.0912, Test Score: 517.0912\n",
      "Epoch: 011, Train Score: 503.1153, Test Score: 503.1153\n",
      "Epoch: 012, Train Score: 527.1135, Test Score: 527.1135\n",
      "Epoch: 013, Train Score: 601.9360, Test Score: 601.9360\n",
      "Epoch: 014, Train Score: 672.5765, Test Score: 672.5765\n",
      "Epoch: 015, Train Score: 661.6836, Test Score: 661.6836\n",
      "Epoch: 016, Train Score: 605.3612, Test Score: 605.3611\n",
      "Epoch: 017, Train Score: 551.2723, Test Score: 551.2723\n",
      "Epoch: 018, Train Score: 519.0516, Test Score: 519.0516\n",
      "Epoch: 019, Train Score: 511.6080, Test Score: 511.6080\n"
     ]
    }
   ],
   "source": [
    "# def train_loop():\n",
    "\n",
    "\"\"\"\n",
    "model = GNNStack(\n",
    "        hidden_dim=16,\n",
    "        num_convolutional_layers=1,\n",
    "        no_dense_layers=1,\n",
    "        direction=\"single\",\n",
    "        dropout_rate=0.2,\n",
    "        task=\"premise\",\n",
    ")\n",
    "\"\"\"\n",
    "writer = Writer(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "# criterion = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "# criterion = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "\n",
    "# criterion = torch.nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "criterion = F.mse_loss\n",
    "\n",
    "# criterion = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "\n",
    "\n",
    "print(\"\\nTraining\")\n",
    "for epoch in range(1, 20):\n",
    "\n",
    "    train(model, train_data, criterion, optimizer)\n",
    "\n",
    "    train_score = test(model, train_data, criterion, writer, testing=False)\n",
    "    test_score = test(model, val_data, criterion, writer, testing=True)\n",
    "    print(f\"Epoch: {epoch:03d}, Train Score: {train_score:.4f}, Test Score: {test_score:.4f}\")\n",
    "\n",
    "    writer.on_step()\n",
    "\n",
    "\n",
    "# return writer\n",
    "# writer = train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ee86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c808858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16656d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c6c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4725e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.x_t_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a9f05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5262a633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e3f7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f3bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = get_data_loader(VAL_ID, BENCHMARK_TYPE, task=LearningTask.PREMISE, **dataset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0af8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(next(iter(val_data)).x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ad516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3858db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ca117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.node_embedding = Embedding(len(config.NODE_TYPE), hidden_channels)\n",
    "\n",
    "\n",
    "        self.conv1 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        self.linear = Linear(hidden_channels, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        \n",
    "        x = input_batch.x\n",
    "        edge_index = input_batch.edge_index\n",
    "        premise_index = input_batch.premise_index    \n",
    "\n",
    "        x = self.node_embedding(x)\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training=self.training) # TODO add dropout parameter?\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = x[premise_index]\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        # Remove inner axis\n",
    "        x = x.squeeze(-1)\n",
    "        \n",
    "    \n",
    "        return x\n",
    "\n",
    "    \n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
